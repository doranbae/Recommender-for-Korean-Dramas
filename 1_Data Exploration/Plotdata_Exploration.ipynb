{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean Drama Plot Text Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my earlier [notebook](google.com), I explored Korea drama's metadata, which I scraped from Wikipedia. While it is rich in other area, Wikipedia did not provide much information on the plot of dramas. I found another website to get the plot data I wanted. Luckily, the plot data was in English (as the site was a drama review / curating site for foreign fans for Korean dramas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's see what we are working with and what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load plot data\n",
    "file_path = 'data/english_texts.pkl'\n",
    "pkl = open(file_path, 'rb')\n",
    "eng_texts = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load titles\n",
    "file_path = 'data/titles.pkl'\n",
    "pkl = open(file_path, 'rb')\n",
    "titles = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 139 drama plot data loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Total {} drama plot data loaded\".format(len(eng_texts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![drama](data/drama_collage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama title:records-of-a-night-watchman\n",
      "-----------------------------\n",
      " MBCs new supernatural fusion sageuk Records of a Night Watchman premiered today and I dont know if its because I set my expectations really low or because the really terrible trailers made me but the show is off to a decent start Granted its a world filled with ghosts magic and dragonsyou have to be prepared for a certain amount of cheese when whats written on the page and the CG outcome isnt always as seamless as youd wish But theres a hefty mythology in play that blends a familiar elementJose\n",
      "=============================\n",
      " \n",
      "Drama title:warm-and-cozy\n",
      "-----------------------------\n",
      " After wading through the arduous portion of denial with a side of noble idiocy we finally get to the good stuff fluttery anticipation of first dates how to seduce your boyfriend without seeming too eager Answer Theres no such thing as too eager Too eagers for people in Episode  Get on with it and what it takes to hang onto your happiness once youve found it Does it involve kisses Because it should   SONG OF THE DAY Beauty Handsome    Because I Like You  Download  Audio clip Adobe Flash Player v\n",
      "=============================\n",
      " \n",
      "Drama title:wonderful-season\n",
      "-----------------------------\n",
      " Wonderful Season is the new KBS weekend family drama that began last weekend and as noted its a hit right out of the gates It had a good leadin with KBSs previous ratings blockbuster Kings Family but dont expect anything like that show in this one a great thing by anyones measureWonderful Season is thoughtful nuanced and heartwarming  I was prompted to check out the drama because of the writer more than anything Lee Kyunghees most recent drama Nice Guy was an intense melo but shes quite capable\n",
      "=============================\n",
      " \n",
      "Drama title:three-musketeers\n",
      "-----------------------------\n",
      " All for one one for all I hope everyones taken this past week to emotionally prepare because this is an ending that throws a lot of things our waysome of them fun and interesting others bittersweet I admit I didnt quite know how a multiseason format would work out but if this first outing is any indication I think well be in good hands by the time the next season rolls around Of course that means we dont get everything tied in a neat bow for the sake of story continuation though theres enough e\n",
      "=============================\n",
      " \n",
      "Drama title:the-time-ive-loved-you\n",
      "-----------------------------\n",
      " Theres nothing thatll surprise anyone here which shouldnt come as a surprise to anyone whos been following along But alas weve finally reached the end of a road with way too many unnecessary detours for its own good one where the destination is so padded and fluffy and two hours long that it theoretically should make up for the journey and whether it does is or not is up to you If nothing else theres at least plenty of Hana and Wonbut you know what they say about having too much of a good thing\n",
      "=============================\n",
      " \n"
     ]
    }
   ],
   "source": [
    "random_draw = np.random.randint(0,139,5)\n",
    "for r in random_draw:\n",
    "    print(\"Drama title:{}\".format(titles[r]))\n",
    "    print(\"-----------------------------\")\n",
    "    print(eng_texts[r][:500])\n",
    "    print(\"=============================\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling on the plot data (*Do not hold your breath yet*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I am going to come clean first. In my first attempt to do topic modeling using gensim library in python, the result was not very good (actually it was bad). I have few ideas how to improve it, but let me show you the current result first. This LDA model uses TFIDF corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/ldamodel_2'\n",
    "ldamodel_2 = LdaModel.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.002*\"yeonjae\" + 0.002*\"dowoo\" + 0.001*\"jiwook\" + 0.001*\"eunseok\" + 0.001*\"kyungah\" + 0.001*\"dowoos\" + 0.000*\"kyungtae\" + 0.000*\"eunsoo\" + 0.000*\"yeonjaes\" + 0.000*\"jaemyung\"')\n",
      "(17, '0.002*\"roo\" + 0.002*\"chashik\" + 0.002*\"yooseul\" + 0.001*\"mi\" + 0.001*\"jinmok\" + 0.001*\"sofia\" + 0.000*\"tan\" + 0.000*\"yooseuls\" + 0.000*\"michelle\" + 0.000*\"piano\"')\n",
      "(83, '0.002*\"yeojin\" + 0.002*\"taehyun\" + 0.001*\"dojoon\" + 0.000*\"chaeyoung\" + 0.000*\"yeojins\" + 0.000*\"hanshin\" + 0.000*\"taehyuns\" + 0.000*\"dojoons\" + 0.000*\"yongpal\" + 0.000*\"scarface\"')\n",
      "(61, '0.002*\"gyun\" + 0.001*\"hyemyeong\" + 0.000*\"woo\" + 0.000*\"dayeon\" + 0.000*\"hyemyeongs\" + 0.000*\"wolmyung\" + 0.000*\"youngshin\" + 0.000*\"chuseong\" + 0.000*\"poong\" + 0.000*\"seho\"')\n",
      "(39, '0.002*\"muryong\" + 0.002*\"wanseung\" + 0.002*\"seolok\" + 0.001*\"yoo\" + 0.001*\"joon\" + 0.001*\"johnny\" + 0.000*\"seung\" + 0.000*\"joonoh\" + 0.000*\"inspector\" + 0.000*\"mi\"')\n",
      "(34, '0.000*\"symbolswhy\" + 0.000*\"hyuns\" + 0.000*\"dongyoons\" + 0.000*\"pursesnatcher\" + 0.000*\"aboutsomething\" + 0.000*\"administrations\" + 0.000*\"pastdue\" + 0.000*\"snorting\" + 0.000*\"evaluations\" + 0.000*\"interwoven\"')\n",
      "(16, '0.000*\"symbolswhy\" + 0.000*\"hyuns\" + 0.000*\"dongyoons\" + 0.000*\"pursesnatcher\" + 0.000*\"aboutsomething\" + 0.000*\"administrations\" + 0.000*\"pastdue\" + 0.000*\"snorting\" + 0.000*\"evaluations\" + 0.000*\"interwoven\"')\n",
      "(99, '0.002*\"jiwoo\" + 0.001*\"jinyi\" + 0.001*\"kai\" + 0.001*\"dosoo\" + 0.001*\"jiwoos\" + 0.000*\"melgidec\" + 0.000*\"mijin\" + 0.000*\"jinyis\" + 0.000*\"dosoos\" + 0.000*\"soran\"')\n"
     ]
    }
   ],
   "source": [
    "print(*ldamodel_2.print_topics(num_topics = 8, num_words = 10), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it all mean? it means for each topic (the first number indicates topic ID), the following words have the highest probability appearing. \n",
    "## The problem is that Korean names are clouding my result!\n",
    "Almost every word are names in Korean: yeonjae, dowoo, jiwook, eunseok, kyungah,wolmyung, poong, seho.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rid of the names will be the first thing on my list in my next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyLDAvis is a great tool to visualize the topic modeling. Please check out and play with the /data/vis/vis.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vis_topic](data/vis/vis_topic.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
